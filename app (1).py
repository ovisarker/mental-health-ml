# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19ktTNE6iZ9tpoRFJ8tET23oRQANVOZqc
"""

# app.py
# ---------------------------------------
# Mental-Health Multiclass Predictor
# - Loads a saved sklearn/imb pipeline (.joblib)
# - Expects pipeline structure: ['prep' -> 'sampler' -> 'clf']
# - Uses paired LabelEncoder (.joblib)
# - Supports 3 targets via simple selector
# ---------------------------------------

import os
import json
import joblib
import pandas as pd
import streamlit as st

st.set_page_config(page_title="Mental Health Classifier", layout="centered")

st.title("🧠 Mental Health Multiclass Classifier")
st.caption("Upload raw feature CSV → model predicts Anxiety / Stress / Depression levels.")

# ---------- Defaults (you can overwrite in the sidebar) ----------
DEFAULTS = {
    "Anxiety": {
        "model":  "final_anxiety_model.joblib",
        "encoder":"final_anxiety_encoder.joblib",
        "meta":   "model_metadata_anxiety_label_early-warning.json",  # optional
    },
    "Stress": {
        "model":  "final_stress_model.joblib",
        "encoder":"final_stress_encoder.joblib",
        "meta":   "model_metadata_stress_label_early-warning.json",   # optional
    },
    "Depression": {
        "model":  "final_depression_model.joblib",
        "encoder":"final_depression_encoder.joblib",
        "meta":   "model_metadata_depression_label_early-warning.json",# optional
    },
}

# ---------- Cache loaders ----------
@st.cache_resource(show_spinner=False)
def load_pipeline(path: str):
    pipe = joblib.load(path)
    # quick sanity checks
    for step in ("prep", "clf"):
        if step not in pipe.named_steps:
            raise ValueError(f"Pipeline must contain a '{step}' step.")
    return pipe

@st.cache_resource(show_spinner=False)
def load_encoder(path: str):
    return joblib.load(path)

def read_metadata(path: str):
    if not path or not os.path.exists(path):
        return {}
    try:
        with open(path, "r") as f:
            return json.load(f)
    except Exception:
        return {}

# ---------- Small helpers ----------
def expected_raw_columns(pipe):
    """Return the raw input column names the pipeline expects (before OneHot)."""
    prep = pipe.named_steps["prep"]
    # Assumes ColumnTransformer with two transformers: ('num', ...), ('cat', ...)
    num_cols = list(prep.transformers_[0][2]) if len(prep.transformers_) > 0 else []
    cat_cols = list(prep.transformers_[1][2]) if len(prep.transformers_) > 1 else []
    return list(num_cols) + list(cat_cols)

def check_missing_or_extra(upload_cols, expected_cols):
    upload_set   = set(upload_cols)
    expected_set = set(expected_cols)
    missing = list(expected_set - upload_set)
    extra   = list(upload_set - expected_set)
    return missing, extra

def safe_inverse_transform(le, y_pred):
    # if encoder exists with classes_, this will name the classes; else fallback to ints
    try:
        return le.inverse_transform(y_pred)
    except Exception:
        return y_pred

# ---------- UI: sidebar controls ----------
st.sidebar.header("Configuration")
target = st.sidebar.selectbox("Choose target", ["Anxiety", "Stress", "Depression"], index=0)

model_path  = st.sidebar.text_input("Model pipeline (.joblib)",  DEFAULTS[target]["model"])
enc_path    = st.sidebar.text_input("Label encoder (.joblib)",    DEFAULTS[target]["encoder"])
meta_path   = st.sidebar.text_input("Metadata (.json, optional)", DEFAULTS[target]["meta"])

# ---------- Load artifacts (lazy) ----------
pipe = None
le   = None
meta = {}

col_info = st.empty()
err_box  = st.empty()

load_cols = st.columns(2)
with load_cols[0]:
    if st.button("🔄 Load model & encoder"):
        try:
            pipe = load_pipeline(model_path)
            le   = load_encoder(enc_path)
            meta = read_metadata(meta_path)
            st.success("Model & encoder loaded.")
            # print quick meta for convenience
            if meta:
                st.caption(f"**Loaded metadata:** target={meta.get('target_block','?')}, "
                           f"model={meta.get('model','?')}, classes={meta.get('classes','?')}")
        except Exception as e:
            err_box.error(f"Failed to load: {e}")

with load_cols[1]:
    if st.button("ℹ️ Show expected input columns"):
        try:
            if pipe is None:
                pipe = load_pipeline(model_path)
            cols = expected_raw_columns(pipe)
            st.write("**Expected raw columns (CSV must contain these):**")
            st.code(", ".join(cols), language="text")
            # Let user download a template
            template = pd.DataFrame([{c: "" for c in cols}])
            st.download_button("Download CSV template", template.to_csv(index=False).encode("utf-8"),
                               file_name="template.csv", mime="text/csv")
        except Exception as e:
            err_box.error(f"Cannot inspect columns: {e}")

st.divider()

# ---------- File upload ----------
uploaded = st.file_uploader("Upload a CSV with the expected raw columns", type=["csv"])

if uploaded is not None:
    try:
        df_in = pd.read_csv(uploaded)
        st.write("**Preview of uploaded data**")
        st.dataframe(df_in.head(20), use_container_width=True)

        # validate columns once we have a pipeline
        if pipe is None:
            pipe = load_pipeline(model_path)
        exp_cols = expected_raw_columns(pipe)
        missing, extra = check_missing_or_extra(df_in.columns, exp_cols)

        if missing:
            st.error(f"Missing required columns ({len(missing)}): {missing[:12]}{' ...' if len(missing)>12 else ''}")
            st.stop()
        if extra:
            st.info(f"Upload has extra columns ({len(extra)}). They’ll be ignored by the pipeline.")

        # ---------- Predict ----------
        if le is None:
            le = load_encoder(enc_path)

        preds = pipe.predict(df_in)
        labels = safe_inverse_transform(le, preds)

        out = df_in.copy()
        out["prediction"] = labels

        # display & download
        st.success("✅ Predictions generated.")
        st.dataframe(out.head(20), use_container_width=True)

        st.download_button(
            "📥 Download predictions CSV",
            out.to_csv(index=False).encode("utf-8"),
            file_name=f"predictions_{target.lower()}.csv",
            mime="text/csv"
        )

        # class list
        try:
            st.caption(f"Model classes: {list(le.classes_)}")
        except Exception:
            pass

    except Exception as e:
        st.error(f"Prediction failed: {e}")

# ---------- Footer ----------
st.caption("Tip: Use the 'Show expected input columns' button to get an exact CSV template.")







